import itertools
import os
import collections
from snakemake.utils import R
from snakemake.exceptions import MissingInputException

shell.prefix("set -eo pipefail; ")
configfile: "/data/khanlab/projects/patidar/Snakemake/config_common.json"
configfile: "/data/khanlab/projects/patidar/Snakemake/config_cluster.json"

localrules: Khanlab_Pipeline
####
#### Targets
####
ALL_SAMPLES = config["samples"]
ALL_FASTQC  = expand("{sample}/fastqc/{sample}_R2_fastqc.html", sample = ALL_SAMPLES)
ALL_QC   = expand("{sample}/{sample}.flagstat.txt", sample = ALL_SAMPLES) + expand("{sample}/{sample}.hotspot.depth", sample = ALL_SAMPLES) + expand("{sample}/{sample}.gt", sample = ALL_SAMPLES) + expand("{sample}/BamQC/qualimapReport.html", sample = ALL_SAMPLES)


ALL_GERMLINE= expand("{sample}/annotation/{sample}.hapcaller", sample = ALL_SAMPLES) + expand("{sample}/annotation/{sample}.platypus", sample = ALL_SAMPLES) + expand("{sample}/annotation/{sample}.freebayes", sample = ALL_SAMPLES)

ALL_ANNOTATED= expand("{sample}/annotation/{sample}.hapcaller.annotated.txt", sample = ALL_SAMPLES) + expand("{sample}/annotation/{sample}.platypus.annotated.txt", sample = ALL_SAMPLES) + expand("{sample}/annotation/{sample}.freebayes.annotated.txt", sample = ALL_SAMPLES)
ALL_SOMATIC = []
somaticPairs = {}
pairedCapture = {}
if len(config['sample_references']) > 0:
	for Tumor in config['sample_references']:
		for Normal in config['sample_references'][Tumor]:
			TumorBam = "{sample}/{sample}.final".format(sample=Tumor)
			NormalBam = "{sample}/{sample}.final".format(sample=Normal)
			pairedCapture[Tumor] = config['sample_captures'][Tumor]
			somaticPairs[Tumor] = [TumorBam + ".bam" , TumorBam + ".bai", NormalBam + ".bam", NormalBam + ".bai"]
			ALL_ANNOTATED += ["{sample}/annotation/{sample}.MuTect.annotated.txt".format(sample=Tumor)]
			ALL_ANNOTATED += ["{sample}/annotation/{sample}.strelka.snvs.annotated.txt".format(sample=Tumor)]
			ALL_ANNOTATED += ["{sample}/annotation/{sample}.strelka.indels.annotated.txt".format(sample=Tumor)]

			## Need these for FormatInput.
			ALL_SOMATIC += ["{sample}/annotation/{sample}.MuTect".format(sample=Tumor)]
			ALL_SOMATIC += ["{sample}/annotation/{sample}.strelka.snvs".format(sample=Tumor)]
			ALL_SOMATIC += ["{sample}/annotation/{sample}.strelka.indels".format(sample=Tumor)]

###########################################################################
###########################################################################
rule Khanlab_Pipeline:
	input: 
		ALL_QC,
		ALL_FASTQC,
		ALL_ANNOTATED,
#		"annotation/AnnotationInput.annotations.final.txt",
#		"annotation/AnnotationInput.anno",
#		"annotation/AnnotationInput.pph2.out"
#	input: ALL_QC, ALL_FASTQC, ALL_GERMLINE, ALL_SOMATIC, "annotation/Test"
#ALL_FASTQC, ALL_SOMATIC, ALL_GERMLINE
############
#	FASTQC
############
rule fastqc:
	input:
		R1="{sample}/{sample}_R1.fastq.gz",
		R2="{sample}/{sample}_R2.fastq.gz"
	output: 
		"{sample}/fastqc/{sample}_R1_fastqc.zip", 
		"{sample}/fastqc/{sample}_R2_fastqc.zip", 
		"{sample}/fastqc/{sample}_R1_fastqc.html", 
		"{sample}/fastqc/{sample}_R2_fastqc.html"
	log: "{sample}/pbs_log/fastqc"
	version: config["fastqc"]
	message: "Running Fastqc on {input[0]}"
	params:
		rulename  = "fastqc",
		batch     = config["job_fastqc"]
	shell: """
	#######################
	module load fastqc/{version}
	fastqc -t ${{SLURM_CPUS_ON_NODE}} -o {wildcards.sample}/fastqc/ -d /scratch {input[R1]} 2>> {log}
	fastqc -t ${{SLURM_CPUS_ON_NODE}} -o {wildcards.sample}/fastqc/ -d /scratch {input[R2]} 2>> {log}
	#######################
	"""
############
#       BWA
############
rule BWA:
	input: 
		R1="{sample}/{sample}_R1.fastq.gz", 
		R2="{sample}/{sample}_R2.fastq.gz",
		ref=config["bwaIndex"]
	output: 
		temp("{sample}/{sample}.bam"),
		temp("{sample}/{sample}.bam.bai")
	log: "{sample}/pbs_log/bwa"
	version: config["bwa"]
	message: "Running bwa on {input[0]}"
	params:
		rulename  = "bwa",
		platform  = config["platform"],
		samtools  = config["samtools"], 
		batch     = config["job_bwa"]
	shell: """
	#######################
	module load bwa/{version}
	module load samtools/{params.samtools}
	bwa mem -M  -t ${{SLURM_CPUS_ON_NODE}} -R \"@RG\\tID:{wildcards.sample}\\tSM:{wildcards.sample}\\tLB:{wildcards.sample}\\tPL:{params.platform}\" {input[ref]} {input.R1} {input.R2} 2> {log}| samtools view -Sbh - |samtools sort -m 30000000000 - {wildcards.sample}/{wildcards.sample}
	samtools index {wildcards.sample}/{wildcards.sample}.bam
	#######################
	"""
############
#       GenotypeFile
############
# Using Older version of samtools for this purpose
rule Genotyping:
	input:
		bam="{sample}/{sample}.final.bam",
		interval=config["genotypeBed"],
		ref=config["reference"],
		vcf2genotype=config["vcf2genotype"],
		vcf2loh=config["vcf2loh"],
	output:
		vcf="{sample}/{sample}.samtools.vcf",
		gt="{sample}/{sample}.gt",
		loh="{sample}/{sample}.loh"
	log: "{sample}/pbs_log/genotyping"
	version: config["samtools_old"]
	message: "Making Genotyping Input file on {input.bam}"
	params:
		rulename  = "genotype",
		batch     = config["job_genotype"],
		dest	  = config["genotypeDest"]
	shell: """
	#######################
	module load samtools/{version}
	samtools mpileup -u -C50 -f {input.ref} -l {input.interval} {input.bam} | bcftools view -gc - >{output.vcf} 2>{log}
	perl {input.vcf2genotype} {output.vcf} >{output.gt} 2>>{log}
	cp -f {output.gt} {params.dest}/{wildcards.sample}.gt 2>>{log}
	perl {input.vcf2loh} {output.vcf} >{output.loh} 2>>{log}
	#######################
	"""	
############
#       BamQC
############
rule BamQC:
	input:
		bam="{sample}/{sample}.final.bam",
		bai="{sample}/{sample}.final.bai",
		interval= lambda wildcards: config['sample_captures'][wildcards.sample].replace('.bed', '.gff')
	output:
		"{sample}/BamQC/qualimapReport.html"
	log: "{sample}/pbs_log/{sample}.bamqc.log"
	version: config["qualimap"]
	message: "Running BamQC on {input[0]}"
	params: 
		rulename = "bamqc",
		batch	 = config["job_qualimap"],
		outdir	 ="{sample}/BamQC",
	shell: """
	#######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	module load qualimap/{version}
	qualimap bamqc -c -bam {input.bam} -outdir {params.outdir} -gff {input.interval} -nt ${{SLURM_CPUS_ON_NODE}} --java-mem-size=${{MEM}}G > {log} 2>&1
	#######################
	"""
############
#       Samtools flagstat
############
rule flagstat:
	input:	"{sample}/{sample}.bam"
	output: "{sample}/{sample}.flagstat.txt"
	log:    "{sample}/pbs_log/flagstat"
	version: config["samtools"]
	message: "Running samtools flagstat on {input[0]}"
	params:
		rulename  = "flagstat",
		batch     = config["job_flagstat"]
	shell: """
	#######################
	module load samtools/{version}
	samtools flagstat {input} > {output}
	#######################
	"""
############
#       Hotspot Coverage
############
rule HotSpotCoverage:
	input:	
		bam="{sample}/{sample}.final.bam",
		interval=config["hotspot_intervals"]
	output: "{sample}/{sample}.hotspot.depth"
	log: "{sample}/pbs_log/hotspotCoverage"
	version: config["bedtools"]
	message: "Running Hotspot Coverage flagstat on {input[0]}"
	params:
		rulename  = "HotSpotCov",
		batch     = config["job_hotspot"],
		samtools  = config["samtools"]
	shell: """
	#######################
	module load samtools/{params.samtools} 
	module load bedtools/{version}
	samtools view -hF 0x400 -q 30 {input.bam} | samtools view -ShF 0x4 - | samtools view -SuF 0x200 - | bedtools coverage -abam - -b {input.interval} >{output}
	
	#######################
	"""

############
#       Picard Mark Duplicates
############
rule Picard_MarkDup:
	input: bam="{sample}/{sample}.bam"
	output: 
		bam=temp("{sample}/{sample}.dd.bam"),
		index=temp("{sample}/{sample}.dd.bam.bai"),
		metrics="{sample}/{sample}.markdup.txt"
	log:    "{sample}/pbs_log/markdup"
	version: config["picard"]
	message: "Running picard mark duplicates on {input[0]}"
	params:
		rulename  = "mark_dup",
		batch     = config["job_markdup"],
		samtools  = config["samtools"]    
	shell: """
	#######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	module load picard/{version}
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $PICARDJARPATH/MarkDuplicates.jar AS=true M={output.metrics} I={input.bam} O={output.bam} REMOVE_DUPLICATES=false VALIDATION_STRINGENCY=SILENT > {log} 2>&1
	module load samtools/{params.samtools}
	samtools index {output.bam}
	######################
	"""
############
#       GATK Best Practices
############
rule GATK:
	input: 	bam="{sample}/{sample}.dd.bam",
		ref=config["reference"],
		phase1=config["1000G_phase1"],
		mills=config["Mills_and_1000G"]
	output:
		bam="{sample}/{sample}.final.bam",
		index="{sample}/{sample}.final.bai",
	log:    "{sample}/pbs_log/gatk"
	version: config["GATK"]
	message: "Running GATK Best practices on {input.bam}"
	params:
		rulename  = "gatk",
		batch     = config["job_gatk"]
	shell: """
	#######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	module load GATK/{version}
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T RealignerTargetCreator -R {input.ref} -known {input.phase1} -known {input.mills} -I {input.bam} -o /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.realignment.intervals > {log} 2>&1
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T IndelRealigner -R {input.ref} -known {input.phase1} -known {input.mills} -I {input.bam} --targetIntervals /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.realignment.intervals -o /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.lr.bam >>{log} 2>&1
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T BaseRecalibrator -R {input.ref} -knownSites {input.phase1} -knownSites {input.mills} -I /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.lr.bam -o /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.recalibration.matrix.txt >>{log} 2>&1
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T PrintReads -R {input.ref} -I /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.lr.bam -o {output.bam} -BQSR /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.recalibration.matrix.txt >>{log} 2>&1
	######################
	"""
############
#       MuTect
############
rule MuTect:
	input:
		lambda wildcards: somaticPairs[wildcards.Tumor],
		ref=config["reference"],
		dbsnp=config["dbsnp"],
		cosmic=config["cosmic"],
		interval=pairedCapture[Tumor]
	output:
		vcf="{Tumor}/{Tumor}.MuTect.vcf",
		call_stats="{Tumor}/{Tumor}.mutect.call_stats.txt",
		coverage="{Tumor}/{Tumor}.mutect.coverage.wig.txt"
	log:	"{Tumor}/pbs_log/mutect"
	version: config["MuTect"]
	params:
		rulename  = "MuTect",
		batch     = config["job_mutect"],
	shell: """
	#######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	gawk '{{print $1 "\t" $2-1 "\t" $3}}' {input.interval} > /lscratch/${{SLURM_JOBID}}/target_intervals.bed
	module load muTect/{version}
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $MUTECTJARPATH -T MuTect \
		--reference_sequence {input.ref} \
		--cosmic {input.cosmic} \
		--dbsnp {input.dbsnp} \
		--input_file:normal {input[0]} \
		--input_file:tumor {input[2]} \
		--intervals  /lscratch/${{SLURM_JOBID}}/target_intervals.bed \
		--coverage_file {output.coverage} \
		--out {output.call_stats} \
		--vcf {output.vcf} \
		> {log} 2>&1
	#######################
	"""
############
#       Strelka
############
rule Strelka:
	input:
		lambda wildcards: somaticPairs[wildcards.Tumor],
		ref=config["reference"],
		config=config["strelka_config"],
		interval=pairedCapture[Tumor]
	output:
		snps="{Tumor}/{Tumor}.strelka.snvs.vcf",
		indels="{Tumor}/{Tumor}.strelka.indels.vcf"
	log:    "{Tumor}/pbs_log/strelka"
	version: config["strelka"]
	params:
		rulename = "Strelka",
		batch    = config["job_strelka"],
		vcftools = config["vcftools"]
	shell: """
	#######################
	module load strelka/{version}
	configureStrelkaWorkflow.pl --normal={input[0]} --tumor={input[2]}\
	--ref={input.ref} --config={input.config} --output-dir=/lscratch/${{SLURM_JOBID}}/strelka > {log} 2>&1
	make -j ${{SLURM_CPUS_PER_TASK}} -f /lscratch/${{SLURM_JOBID}}/strelka/Makefile 2>> {log}
	module load vcftools/{params.vcftools}
	vcftools --vcf /lscratch/${{SLURM_JOBID}}/strelka/results/all.somatic.snvs.vcf --bed {input.interval} --out {output.snps} --recode --keep-INFO-all
	mv {output.snps}.recode.vcf {output.snps}
	vcftools --vcf /lscratch/${{SLURM_JOBID}}/strelka/results/all.somatic.indels.vcf --bed {input.interval} --out {output.indels} --recode --keep-INFO-all
	mv {output.indels}.recode.vcf {output.indels}
	#######################
	"""
############
#       HaplotypeCaller
############
rule Haplotype_Caller :
	input:
		bam="{sample}/{sample}.final.bam",
		bai="{sample}/{sample}.final.bai",
		ref=config["reference"],
                dbsnp=config["dbsnp"],
		interval= lambda wildcards: config['sample_captures'][wildcards.sample]
	output:
		vcf="{sample}/{sample}.hapcaller.vcf"
	log:    "{sample}/pbs_log/hapcaller"
	version: config["GATK"]
	params:
		rulename = "HapCall",
		batch    = config["job_gatk"]
	shell: """
	#######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	module load GATK/{version}
	gawk '{{print $1 "\t" $2-1 "\t" $3}}' {input.interval} > /lscratch/${{SLURM_JOBID}}/target_intervals.bed
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T HaplotypeCaller -R {input.ref} -I {input.bam} -L /lscratch/${{SLURM_JOBID}}/target_intervals.bed -o {output.vcf} --dbsnp {input.dbsnp} -mbq 20 -mmq 30 -log {log}

	#######################
	"""
############
#       Platypus
############
rule  Platypus:
	input:
		bam="{sample}/{sample}.final.bam",
		bai="{sample}/{sample}.final.bai",
		ref=config["reference"],
		interval= lambda wildcards: config['sample_captures'][wildcards.sample]
	output:
		vcf="{sample}/{sample}.platypus.vcf"
	log:    "{sample}/pbs_log/platypus"
	version: config["platypus"]
	params:
		rulename = "platypus",
		batch    = config["job_platypus"]
	shell: """
	#######################
	module load platypus/{version}
	platypus callVariants --nCPU=${{SLURM_CPUS_ON_NODE}} --bufferSize=1000000 --maxReads=100000000 --bamFiles={input.bam} --regions={input.interval} --output={output.vcf} --refFile={input.ref} --logFileName={log} 
	#######################
	"""
############
#       FreeBayes
############
rule  FreeBayes:
	input:
		bam="{sample}/{sample}.final.bam",
		bai="{sample}/{sample}.final.bai",
		ref=config["reference"],
		interval= lambda wildcards: config['sample_captures'][wildcards.sample]
	output:
		vcf="{sample}/{sample}.freebayes.vcf"
	log:    "{sample}/pbs_log/freebayes"
	version: config["freebayes"]
	params:
		rulename = "freebayes",
		batch    = config["job_freebayes"],
		vcftools = config["vcftools"]
	shell: """
	#######################
	module load freebayes/{version}
	freebayes -f {input.ref} --haplotype-length 50 -b {input.bam} -v {output.vcf} > {log} 2>&1
	
	
	module load vcftools/{params.vcftools}
	vcftools --vcf {output} --bed {input.interval} --out {output.vcf} --recode --keep-INFO-all
	mv {output.vcf}.recode.vcf {output.vcf}
	
	#######################
	"""


############
#	snpEff and vcf2txt
############
rule snpEff:
	input:
		vcf="{sample}/{sample}.{base}.vcf",
		ref=config["reference"],
		snpEff_config=config["snpEff_config"],
		vcf2txt=config["vcf2txt"],
	output:
		eff="{sample}/{sample}.{base}.snpEff.vcf",
		txt="{sample}/annotation/{sample}.{base}"
	log: "{sample}/pbs_log/{base}.snpEff"
	version: config["snpEff"]
	params:
		rulename      ="snpEff",
		batch	      =config["job_snpeff"],
		snpEff_genome =config["snpEff_genome"]
	shell: """
	#######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	module load snpEff/{version}
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar ${{SNPEFFHOME}}/SnpSift.jar dbnsfp -c {input.snpEff_config} -a {input.vcf} | java -Xmx${{MEM}}g -jar ${{SNPEFFHOME}}/snpEff.jar -t -canon {params.snpEff_genome} > {output.eff} 2> {log}
	perl {input.vcf2txt} {output.eff} >{output.txt}
	#######################
	"""
############
#	MakeList
############
rule FormatInput:
	input:	somatic=ALL_SOMATIC, 
		germline=ALL_GERMLINE
	output: 
		"annotation/AnnotationInput.anno", 
		"annotation/AnnotationInput.pph",
		"annotation/AnnotationInput.sift",
	log: "log/FormatInput"
	version: config["annovar"]
	params:
		rulename   = "FormatInput",
		batch      = config["job_annovar"],
		convertor  = config["annoInput"],
	shell: """
	#######################
	module load annovar/{version}
	echo {input.germline}
	echo {input.somatic}
	LIST=`echo {input.germline} {input.somatic}|sed -e 's/,//g'`
	cut -f 1-5 ${{LIST}}|sort |uniq >"annotation/AnnotationInput"
	perl {params.convertor} "annotation/AnnotationInput" 2>{log}
	#######################
	"""
############
#       MakeList
############
rule Annotation:
	input: "annotation/AnnotationInput.anno",
	output:
		"annotation/AnnotationInput.docm"
	log: "log/Annovar"
	version: config["annovar"]
	params:
		rulename   = "Annotation",
		batch      = config["job_annovar"],
		RefData    = config["annovar_data"],
		build      = config["build"],
		TableAnnovar=config["Annovar"],
		custom     =config["customAnno"]
	shell: """
	#######################
	module load annovar/{version}
	perl {params.TableAnnovar} annotation AnnotationInput {params.custom} 2>>{log}
	#######################
	"""
############
#       SIFT
############
rule SIFT:
	input: "annotation/AnnotationInput.sift",
	output: "annotation/AnnotationInput.sift.out"
	log: "log/SIFT"
	version: config["SIFT"]
	params:
		rulename   = "SIFT",
		batch      = config["job_SIFT"],
		convertor  = config["SiftParse"],
		build      = config["SIFTbuild"]
	shell: """
	#######################
	module load python/2.7.4
	module load SIFT/{version}
	DIR=`pwd`
	cd ${{DIR}}/`dirname {input}`
	FILE=`basename {input}`
	SIFT_exome_nssnvs.pl -i ${{FILE}} -d /fdb/sift/Human_db_37 -o $SIFT_SCRATCHDIR -z ${{DIR}}/`dirname {input}`/${{FILE}}.sift_predictions.tsv
	{params.convertor} ${{DIR}}/`dirname {input}`/${{FILE}}.sift_predictions.tsv >${{DIR}}/`dirname {input}`/${{FILE}}.out
	#######################
	"""
############
#       PPH2
############
rule PPH2:
	input: "annotation/AnnotationInput.pph",
	output: "annotation/AnnotationInput.pph2.out"
	log: "log/PPH2"
	version: config["polyphen2"]
	params:
		rulename   = "PPH2",
		batch      = config["job_PPH2"],
		convertor  = config["PPH2Parse"],
		build      = config["SIFTbuild"]
	shell: """
	#######################
	module load polyphen2/{version}
	mapsnps.pl -c -g hg19 -U -y {input}.intermediate {input} 2>{log}
	pph_swarm.pl {input}.intermediate -d /scratch/`whoami`/${{RANDOM}}${{RANDOM}} -o annotation/AnnotationInput.pph2.intermediate.txt --partition ${{SLURM_JOB_PARTITION}} --block 
	perl {params.convertor}  annotation/AnnotationInput.pph2.intermediate.txt >{output} 2>>{log}
	rm -rf {input}.intermediate annotation/AnnotationInput.pph2.intermediate.txt
	mv pph_* log/ 
	#######################
	"""
############
#	Combine Annotation
############
rule CombineAnnotation:
	input:
		anno="annotation/AnnotationInput.docm", 
		sift="annotation/AnnotationInput.sift.out", 
		pph2="annotation/AnnotationInput.pph2.out",
	output: "annotation/AnnotationInput.annotations.final.txt"
	log: "log/CombineAnnotation"
	version: "1.0"
	params:
		rulename   = "combine",
		batch	   = config["job_Combine"],
		convertor  = config["CombineAnno"],
		geneanno   = config["GeneAnno"],
		dataDir    = config["annovar_data"]
	shell: """
	#######################
	echo "annotation/AnnotationInput
annotation/AnnotationInput.anno.gene
annotation/AnnotationInput.anno.exac.3
annotation/AnnotationInput.anno.clinseq
annotation/AnnotationInput.anno.cadd
annotation/AnnotationInput.sift.out
annotation/AnnotationInput.pph2.out
annotation/AnnotationInput.anno.clinvar
annotation/AnnotationInput.hgmd
annotation/AnnotationInput.match
annotation/AnnotationInput.docm
annotation/AnnotationInput.mcg
annotation/AnnotationInput.anno.pcg" >annotation/list
	perl {params.convertor} annotation/list >{output}.tmp
	perl {params.geneanno} {params.dataDir}/hg19_ACMG.txt {output}.tmp >{output}
	rm -rf {output}.tmp
	#######################
	"""
############
#	Add Annotation back to sample level file 
############
rule AttachAnnotation:
	input:
		txt="{sample}/annotation/{sample}.{base}",
		ref="annotation/AnnotationInput.annotations.final.txt"
	output:
		txt="{sample}/annotation/{sample}.{base}.annotated.txt"
	log: "log/attach_annotation"
	version: "1.0"
	params:
		rulename   = "add",
		batch      = config["job_addbackann"],
		convertor  = config["addBack"]
	shell: """
	#######################
	perl {params.convertor} {input.ref} {input.txt} >{output.txt} 2>{log}
	#######################
	"""
