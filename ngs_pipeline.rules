import itertools
import os
import collections
from snakemake.utils import R
from snakemake.exceptions import MissingInputException
try:
    NGS_PIPELINE=os.environ['NGS_PIPELINE']
except KeyError:
    NGS_PIPELINE="/data/khanlab/projects/patidar/Serpentine"
    pass

shell.prefix("set -eo pipefail; ")
configfile: "/data/khanlab/projects/patidar/Snakemake/config_common.json"
configfile: "/data/khanlab/projects/patidar/Snakemake/config_cluster.json"

localrules: Khanlab_Pipeline
####
#### Targets
####
SUBS  = []
for subject,samples in config['subject'].items():
	SUBS.append(subject)

ALL_SAMPLES = config["samples"]
ALL_FASTQC  = expand("{sample}/qc/fastqc/{sample}_R2_fastqc.html", sample = ALL_SAMPLES)
ALL_QC   = expand("{sample}/qc/{sample}.flagstat.txt", sample = ALL_SAMPLES) + expand("{sample}/qc/{sample}.hotspot.depth", sample = ALL_SAMPLES) + expand("{sample}/qc/{sample}.gt", sample = ALL_SAMPLES) + expand("{sample}/qc/BamQC/qualimapReport.html", sample = ALL_SAMPLES)


ALL_GERMLINE= expand("{sample}/annotation/{sample}.hapcaller", sample = ALL_SAMPLES) + expand("{sample}/annotation/{sample}.platypus", sample = ALL_SAMPLES) + expand("{sample}/annotation/{sample}.freebayes", sample = ALL_SAMPLES) + expand("{sample}/annotation/{sample}.bam2mpg.snps", sample = ALL_SAMPLES),

ALL_ANNOTATED= expand("{sample}/annotation/{sample}.hapcaller.annotated.txt", sample = ALL_SAMPLES) + expand("{sample}/annotation/{sample}.platypus.annotated.txt", sample = ALL_SAMPLES) + expand("{sample}/annotation/{sample}.freebayes.annotated.txt", sample = ALL_SAMPLES)
###########################################################################
###########################################################################
ALL_SUBJECT_BAMS = {} 
for Subject  in config['subject']:
	ALL_SUBJECT_BAMS[Subject] = expand("{sample}/{sample}.bwa.final.bam", sample = config['subject'][Subject])
#print(ALL_SUBJECT_BAMS)
###########################################################################
###########################################################################
ALL_SOMATIC = []
somaticPairs = {}
pairedCapture = {}
if len(config['sample_references']) > 0:
	for Tumor in config['sample_references']:
		for Normal in config['sample_references'][Tumor]:
			TumorBam = "{sample}/{sample}.bwa.final".format(sample=Tumor)
			NormalBam = "{sample}/{sample}.bwa.final".format(sample=Normal)
			pairedCapture[Tumor] = config['sample_captures'][Tumor]
			somaticPairs[Tumor] = [TumorBam + ".bam" , TumorBam + ".bai", NormalBam + ".bam", NormalBam + ".bai"]
			ALL_ANNOTATED += ["{sample}/annotation/{sample}.MuTect.annotated.txt".format(sample=Tumor)]
			ALL_ANNOTATED += ["{sample}/annotation/{sample}.strelka.snvs.annotated.txt".format(sample=Tumor)]
			ALL_ANNOTATED += ["{sample}/annotation/{sample}.strelka.indels.annotated.txt".format(sample=Tumor)]

			## Need these for FormatInput.
			ALL_SOMATIC += ["{sample}/annotation/{sample}.MuTect".format(sample=Tumor)]
			ALL_SOMATIC += ["{sample}/annotation/{sample}.strelka.snvs".format(sample=Tumor)]
			ALL_SOMATIC += ["{sample}/annotation/{sample}.strelka.indels".format(sample=Tumor)]
###########################################################################
###########################################################################
ALL_EXPRESSED =[]
expressedPairs = {}
if len(config['sample_RNASeq']) > 0:
	for Tumor in config['sample_RNASeq']:
		for RNASample in config['sample_RNASeq'][Tumor]:
		#	MutationFile = "{sample}/annotation/{sample}.MuTect.annotated.txt".format(sample=Tumor)
			RNASeqBam    = "/data/khanlab/projects/working_DATA/" + RNASample + "/" + RNASample + ".Processed/" + RNASample + ".bam" 
		#	expressedPairs[Tumor] = [MutationFile, RNASeqBam]
			expressedPairs[Tumor] = RNASeqBam
			ALL_EXPRESSED += ["{sample}/annotation/{sample}.MuTect.annotated.expressed.txt".format(sample=Tumor)]
			ALL_EXPRESSED += ["{sample}/annotation/{sample}.strelka.snvs.annotated.expressed.txt".format(sample=Tumor)]
			ALL_EXPRESSED += ["{sample}/annotation/{sample}.strelka.indels.annotated.expressed.txt".format(sample=Tumor)]
			ALL_EXPRESSED += ["{sample}/annotation/{sample}.hapcaller.annotated.expressed.txt".format(sample=Tumor)]
			ALL_EXPRESSED += ["{sample}/annotation/{sample}.platypus.annotated.expressed.txt".format(sample=Tumor)]
			ALL_EXPRESSED += ["{sample}/annotation/{sample}.freebayes.annotated.expressed.txt".format(sample=Tumor)]
###########################################################################
###########################################################################
rule Khanlab_Pipeline:
	input: 
		ALL_QC,
		ALL_FASTQC,
		expand("{subject}/{subject}.hapcaller.snvs.vcf", subject= SUBS),
		ALL_ANNOTATED,
		ALL_EXPRESSED,
############
#	FASTQC
############
rule fastqc:
	input:
		R1="/data/khanlab/projects/DATA/{sample}/{sample}_R1.fastq.gz",
		R2="/data/khanlab/projects/DATA/{sample}/{sample}_R2.fastq.gz"
	output: 
		"{sample}/qc/fastqc/{sample}_R1_fastqc.zip", 
		"{sample}/qc/fastqc/{sample}_R2_fastqc.zip", 
		"{sample}/qc/fastqc/{sample}_R1_fastqc.html", 
		"{sample}/qc/fastqc/{sample}_R2_fastqc.html"
	log: "{sample}/pbs_log/fastqc"
	version: config["fastqc"]
	message: "Running Fastqc on {input[0]}"
	params:
		rulename  = "fastqc",
		batch     = config["job_fastqc"]
	shell: """
	#######################
	module load fastqc/{version}
	fastqc -t 6 -o {wildcards.sample}/qc/fastqc/ -d /scratch {input[R1]} 2>> {log}
	fastqc -t 6 -o {wildcards.sample}/qc/fastqc/ -d /scratch {input[R2]} 2>> {log}
	#######################
	"""
############
#       BWA
############
rule BWA:
	input: 
		R1="/data/khanlab/projects/DATA/{sample}/{sample}_R1.fastq.gz", 
		R2="/data/khanlab/projects/DATA/{sample}/{sample}_R2.fastq.gz",
		ref=config["bwaIndex"]
	output: 
		temp("{sample}/{sample}.bwa.bam"),
		temp("{sample}/{sample}.bwa.bam.bai")
	log: "{sample}/pbs_log/bwa"
	version: config["bwa"]
	message: "Running bwa on {input[0]}"
	params:
		rulename  = "bwa",
		platform  = config["platform"],
		samtools  = config["samtools"], 
		batch     = config["job_bwa"]
	shell: """
	#######################
	module load bwa/{version}
	module load samtools/{params.samtools}
	bwa mem -M  -t ${{SLURM_CPUS_ON_NODE}} -R \"@RG\\tID:{wildcards.sample}\\tSM:{wildcards.sample}\\tLB:{wildcards.sample}\\tPL:{params.platform}\" {input[ref]} {input.R1} {input.R2} 2> {log}| samtools view -Sbh - |samtools sort -m 30000000000 - {wildcards.sample}/{wildcards.sample}.bwa
	samtools index {wildcards.sample}/{wildcards.sample}.bwa.bam
	#######################
	"""
############
#	Novoalign
############
rule Novoalign:
	input:
		R1="/data/khanlab/projects/DATA/{sample}/{sample}_R1.fastq.gz",
		R2="/data/khanlab/projects/DATA/{sample}/{sample}_R2.fastq.gz",
		index="/fdb/novoalign/chr_all_hg19.nbx"
	output:
		temp("{sample}/{sample}.novo.bam"),
		temp("{sample}/{sample}.novo.bam.bai")
	log: "{sample}/pbs_log/novoalign"
	version: config["novocraft"]
	params:
		rulename  = "novoalign",
		batch     = config["job_novoalign"],
		samtools  = config["samtools"],
		platform  = config["platform"]
	shell: """
	#######################
	module load samtools/{params.samtools}
	module load novocraft/{version}
	mpiexec  -envall -host `scontrol show hostname ${{SLURM_NODELIST}} | paste -d',' -s` -np ${{SLURM_NTASKS}} novoalignMPI -F STDFQ -o SAM \"@RG\\tID:{wildcards.sample}\\tSM:{wildcards.sample}\\tLB:{wildcards.sample}\\tPL:{params.platform}\" -t 250 --hlimit 7 -p 5,2 -l 30 -e 100 -i 200 100 -a AGATCGGAAGAGCGGTTCAGCAGGAATGCCGAG AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA -H -d {input.index} -f {input.R1} {input.R2} | samtools view -uS - | samtools sort -m 30000000000 - {wildcards.sample}/{wildcards.sample}.novo
	samtools index {wildcards.sample}/{wildcards.sample}.novo.bam 
	#######################
	"""
############
#       GenotypeFile
############
# Using Older version of samtools for this purpose
rule Genotyping:
	input:
		bam="{sample}/{sample}.bwa.final.bam",
		interval=config["genotypeBed"],
		ref=config["reference"],
		vcf2genotype=NGS_PIPELINE + "/scripts/" + config["vcf2genotype"],
		vcf2loh=NGS_PIPELINE + "/scripts/" + config["vcf2loh"],
	output:
		vcf="{sample}/calls/{sample}.samtools.vcf",
		gt="{sample}/qc/{sample}.gt",
		loh="{sample}/qc/{sample}.loh"
	log: "{sample}/pbs_log/genotyping"
	version: config["samtools_old"]
	message: "Making Genotyping Input file on {input.bam}"
	params:
		rulename  = "genotype",
		batch     = config["job_genotype"],
		dest	  = config["genotypeDest"]
	shell: """
	#######################
	module load samtools/{version}
	samtools mpileup -u -C50 -f {input.ref} -l {input.interval} {input.bam} | bcftools view -gc - >{output.vcf} 2>{log}
	perl {input.vcf2genotype} {output.vcf} >{output.gt} 2>>{log}
	cp -f {output.gt} {params.dest}/{wildcards.sample}.gt 2>>{log}
	perl {input.vcf2loh} {output.vcf} >{output.loh} 2>>{log}
	#######################
	"""	
############
#       BamQC
############
rule BamQC:
	input:
		bam="{sample}/{sample}.bwa.final.bam",
		bai="{sample}/{sample}.bwa.final.bai",
		interval= lambda wildcards: config['sample_captures'][wildcards.sample].replace('.bed', '.gff')
	output:
		"{sample}/qc/BamQC/qualimapReport.html"
	log: "{sample}/pbs_log/{sample}.bamqc.log"
	version: config["qualimap"]
	message: "Running BamQC on {input[0]}"
	params: 
		rulename = "bamqc",
		batch	 = config["job_qualimap"],
		outdir	 ="{sample}/qc/BamQC",
	shell: """
	#######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	module load qualimap/{version}
	qualimap bamqc -c -bam {input.bam} -outdir {params.outdir} -gff {input.interval} -nt ${{SLURM_CPUS_ON_NODE}} --java-mem-size=${{MEM}}G > {log} 2>&1
	#######################
	"""
############
#       Samtools flagstat
############
rule flagstat:
	input:	"{sample}/{sample}.bwa.bam"
	output: "{sample}/qc/{sample}.flagstat.txt"
	log:    "{sample}/pbs_log/flagstat"
	version: config["samtools"]
	message: "Running samtools flagstat on {input[0]}"
	params:
		rulename  = "flagstat",
		batch     = config["job_flagstat"]
	shell: """
	#######################
	module load samtools/{version}
	samtools flagstat {input} > {output}
	#######################
	"""
############
#       Hotspot Coverage
############
rule HotSpotCoverage:
	input:	
		bam="{sample}/{sample}.bwa.final.bam",
		interval=config["hotspot_intervals"]
	output: "{sample}/qc/{sample}.hotspot.depth"
	log: "{sample}/pbs_log/hotspotCoverage"
	version: config["bedtools"]
	message: "Running Hotspot Coverage flagstat on {input[0]}"
	params:
		rulename  = "HotSpotCov",
		batch     = config["job_hotspot"],
		samtools  = config["samtools"]
	shell: """
	#######################
	module load samtools/{params.samtools} 
	module load bedtools/{version}
	samtools view -hF 0x400 -q 30 {input.bam} | samtools view -ShF 0x4 - | samtools view -SuF 0x200 - | bedtools coverage -abam - -b {input.interval} >{output}
	#######################
	"""
############
#       Picard Mark Duplicates
############
rule Picard_MarkDup:
	input:
		bam="{sample}/{sample}.{base}.bam",
		bai="{sample}/{sample}.{base}.bam.bai"
		
	output: 
		bam=temp("{sample}/{sample}.{base}.dd.bam"),
		index=temp("{sample}/{sample}.{base}.dd.bam.bai"),
		metrics="{sample}/qc/{base}.markdup.txt"
	log:    "{sample}/pbs_log/{base}.markdup"
	version: config["picard"]
	message: "Running picard mark duplicates on {input[0]}"
	params:
		rulename  = "mark_dup",
		batch     = config["job_markdup"],
		samtools  = config["samtools"]    
	shell: """
	#######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	module load picard/{version}
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $PICARDJARPATH/MarkDuplicates.jar AS=true M={output.metrics} I={input.bam} O={output.bam} REMOVE_DUPLICATES=false VALIDATION_STRINGENCY=SILENT > {log} 2>&1
	module load samtools/{params.samtools}
	samtools index {output.bam}
	######################
	"""
############
#       GATK Best Practices
############
rule GATK:
	input: 	bam="{sample}/{sample}.bwa.dd.bam",
		bai="{sample}/{sample}.bwa.dd.bam.bai",
		ref=config["reference"],
		phase1=config["1000G_phase1"],
		mills=config["Mills_and_1000G"]
	output:
		bam=protected("{sample}/{sample}.bwa.final.bam"),
		index=protected("{sample}/{sample}.bwa.final.bai"),
	log:    "{sample}/pbs_log/gatk"
	version: config["GATK"]
	message: "Running GATK Best practices on {input.bam}"
	params:
		rulename  = "gatk",
		batch     = config["job_gatk"]
	shell: """
	#######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	module load GATK/{version}
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T RealignerTargetCreator -R {input.ref} -known {input.phase1} -known {input.mills} -I {input.bam} -o /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.realignment.intervals > {log} 2>&1
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T IndelRealigner -R {input.ref} -known {input.phase1} -known {input.mills} -I {input.bam} --targetIntervals /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.realignment.intervals -o /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.lr.bam >>{log} 2>&1
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T BaseRecalibrator -R {input.ref} -knownSites {input.phase1} -knownSites {input.mills} -I /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.lr.bam -o /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.recalibration.matrix.txt >>{log} 2>&1
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T PrintReads -R {input.ref} -I /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.lr.bam -o {output.bam} -BQSR /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.recalibration.matrix.txt >>{log} 2>&1
	######################
	"""
############
#	Bam2MPG
############
rule Bam2MPG:
	input:
		bam="{sample}/{sample}.novo.dd.bam",
		bai="{sample}/{sample}.novo.dd.bam.bai",
		ref=config["reference"],
	output:
		snps="{sample}/calls/{sample}.bam2mpg.snps.vcf",
		indel="{sample}/calls/{sample}.bam2mpg.indels.vcf"
	log: "{sample}/pbs_log/bam2mpg"
	version: config["bam2mpg"]
	message: "Running Bam2MPG on {input.bam}"
	params:
		rulename  = "bam2mpg",
		batch     = config["job_bam2mpg"],
		samtools  = config["samtools"],
		vcftools  = config["vcftools"]
	shell: """
	#######################
	module load bam2mpg/{version}
	for CHR in `seq 1 22` X Y;
	do
	bam2mpg --qual_filter 20 -bam_filter '-q31' --region chr${{CHR}} --only_nonref --snv_vcf /lscratch/${{SLURM_JOBID}}/chr${{CHR}}{wildcards.sample}.snps.vcf --div_vcf /lscratch/${{SLURM_JOBID}}/chr${{CHR}}{wildcards.sample}.indel.vcf {input.ref} {input.bam}
	done

	for CHR in `seq 1 22` X Y
	do
		bgzip /lscratch/${{SLURM_JOBID}}/chr${{CHR}}{wildcards.sample}.snps.vcf
		bgzip /lscratch/${{SLURM_JOBID}}/chr${{CHR}}{wildcards.sample}.indel.vcf
		tabix -p vcf /lscratch/${{SLURM_JOBID}}/chr${{CHR}}{wildcards.sample}.snps.vcf.gz
		tabix -p vcf /lscratch/${{SLURM_JOBID}}/chr${{CHR}}{wildcards.sample}.indel.vcf.gz
	done
	module load vcftools/{params.vcftools}
	vcf-concat /lscratch/${{SLURM_JOBID}}/chr*{wildcards.sample}.snps.vcf.gz >{output.snps}
	vcf-concat /lscratch/${{SLURM_JOBID}}/chr*{wildcards.sample}.indel.vcf.gz >{output.indel}
	#######################
	"""
############
#       MuTect
############
rule MuTect:
	input:
		lambda wildcards: somaticPairs[wildcards.Tumor],
		ref=config["reference"],
		dbsnp=config["dbsnp"],
		cosmic=config["cosmic"],
		interval=pairedCapture[Tumor]
	output:
		vcf="{Tumor}/calls/{Tumor}.MuTect.vcf",
		call_stats="{Tumor}/qc/{Tumor}.mutect.call_stats.txt",
		coverage="{Tumor}/qc/{Tumor}.mutect.coverage.wig.txt"
	log:	"{Tumor}/pbs_log/mutect"
	version: config["MuTect"]
	params:
		rulename  = "MuTect",
		batch     = config["job_mutect"],
	shell: """
	#######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	gawk '{{print $1 "\t" $2-1 "\t" $3}}' {input.interval} > /lscratch/${{SLURM_JOBID}}/target_intervals.bed
	module load muTect/{version}
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $MUTECTJARPATH -T MuTect \
		--reference_sequence {input.ref} \
		--cosmic {input.cosmic} \
		--dbsnp {input.dbsnp} \
		--input_file:normal {input[0]} \
		--input_file:tumor {input[2]} \
		--intervals  /lscratch/${{SLURM_JOBID}}/target_intervals.bed \
		--coverage_file {output.coverage} \
		--out {output.call_stats} \
		--vcf {output.vcf} \
		> {log} 2>&1
	#######################
	"""
############
#       Strelka
############
rule Strelka:
	input:
		lambda wildcards: somaticPairs[wildcards.Tumor],
		ref=config["reference"],
		config=config["strelka_config"],
		interval=pairedCapture[Tumor]
	output:
		snps="{Tumor}/calls/{Tumor}.strelka.snvs.vcf",
		indels="{Tumor}/calls/{Tumor}.strelka.indels.vcf"
	log:    "{Tumor}/pbs_log/strelka"
	version: config["strelka"]
	params:
		rulename = "Strelka",
		batch    = config["job_strelka"],
		vcftools = config["vcftools"]
	shell: """
	#######################
	module load strelka/{version}
	configureStrelkaWorkflow.pl --normal={input[0]} --tumor={input[2]}\
	--ref={input.ref} --config={input.config} --output-dir=/lscratch/${{SLURM_JOBID}}/strelka > {log} 2>&1
	make -j ${{SLURM_CPUS_PER_TASK}} -f /lscratch/${{SLURM_JOBID}}/strelka/Makefile 2>> {log}
	module load vcftools/{params.vcftools}
	vcftools --vcf /lscratch/${{SLURM_JOBID}}/strelka/results/passed.somatic.snvs.vcf --bed {input.interval} --out {output.snps} --recode --keep-INFO-all
	mv {output.snps}.recode.vcf {output.snps}
	vcftools --vcf /lscratch/${{SLURM_JOBID}}/strelka/results/passed.somatic.indels.vcf --bed {input.interval} --out {output.indels} --recode --keep-INFO-all
	mv {output.indels}.recode.vcf {output.indels}
	#######################
	"""
############
#       HaplotypeCaller
############
rule Haplotype_Caller :
	input:
		bam="{sample}/{sample}.bwa.final.bam",
		bai="{sample}/{sample}.bwa.final.bai",
		ref=config["reference"],
                dbsnp=config["dbsnp"],
		interval= lambda wildcards: config['sample_captures'][wildcards.sample]
	output:
		vcf="{sample}/calls/{sample}.hapcaller.vcf"
	log:    "{sample}/pbs_log/hapcaller"
	version: config["GATK"]
	params:
		rulename = "HapCall",
		batch    = config["job_gatk"]
	shell: """
	#######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	module load GATK/{version}
	gawk '{{print $1 "\t" $2-1 "\t" $3}}' {input.interval} > /lscratch/${{SLURM_JOBID}}/target_intervals.bed
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T HaplotypeCaller -R {input.ref} -I {input.bam} -L /lscratch/${{SLURM_JOBID}}/target_intervals.bed -o {output.vcf} --dbsnp {input.dbsnp} -mbq 20 -mmq 30 -log {log}

	#######################
	"""
############
# Subject Hapcaller
############
rule HapCall_Subject:
	input:
		bams=lambda wildcards: ALL_SUBJECT_BAMS[wildcards.subject],
		ref=config["reference"],
		dbsnp=config["dbsnp"]
	output:
		vcf="{subject}/{subject}.hapcaller.snvs.vcf"
	log: "log/{subject}.hapcaller"
	version: config["GATK"]
	params:
		rulename = "HC",
		batch    = config["job_gatk"]
	run:
		bamFiles = " ".join('-I ' + bam for bam in input.bams)
		shell("""
	#######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	module load GATK/{version}
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T HaplotypeCaller -R {input.ref} {bamFiles} -o {output.vcf} --dbsnp {input.dbsnp} -mbq 20 -mmq 30 -log {log}
	#######################
	""")
############
#       Platypus
############
rule  Platypus:
	input:
		bam="{sample}/{sample}.bwa.final.bam",
		bai="{sample}/{sample}.bwa.final.bai",
		ref=config["reference"],
		interval= lambda wildcards: config['sample_captures'][wildcards.sample]
	output:
		vcf="{sample}/calls/{sample}.platypus.vcf"
	log:    "{sample}/pbs_log/platypus"
	version: config["platypus"]
	params:
		rulename = "platypus",
		batch    = config["job_platypus"]
	shell: """
	#######################
	module load platypus/{version}
	platypus callVariants --nCPU=${{SLURM_CPUS_ON_NODE}} --bufferSize=1000000 --maxReads=100000000 --bamFiles={input.bam} --regions={input.interval} --output={output.vcf} --refFile={input.ref} --logFileName={log} 
	#######################
	"""
############
#       FreeBayes
############
rule  FreeBayes:
	input:
		bam="{sample}/{sample}.bwa.final.bam",
		bai="{sample}/{sample}.bwa.final.bai",
		ref=config["reference"],
		interval= lambda wildcards: config['sample_captures'][wildcards.sample]
	output:
		vcf="{sample}/calls/{sample}.freebayes.vcf"
	log:    "{sample}/pbs_log/freebayes"
	version: config["freebayes"]
	params:
		rulename = "freebayes",
		batch    = config["job_freebayes"],
		vcftools = config["vcftools"]
	shell: """
	#######################
	module load freebayes/{version}
	freebayes -f {input.ref} --haplotype-length 50 -b {input.bam} -v {output.vcf} > {log} 2>&1
	module load vcftools/{params.vcftools}
	vcftools --vcf {output} --bed {input.interval} --out {output.vcf} --recode --keep-INFO-all
	mv {output.vcf}.recode.vcf {output.vcf}
	#######################
	"""
############
#	snpEff and vcf2txt
############
rule snpEff:
	input:
		vcf="{sample}/calls/{sample}.{base}.vcf",
		ref=config["reference"],
		snpEff_config=config["snpEff_config"],
		vcf2txt=NGS_PIPELINE + "/scripts/" + config["vcf2txt"]
	output:
		eff="{sample}/calls/{sample}.{base}.snpEff.vcf",
		txt=temp("{sample}/annotation/{sample}.{base}")
	log: "{sample}/pbs_log/{base}.snpEff"
	version: config["snpEff"]
	params:
		rulename      ="snpEff",
		batch	      =config["job_snpeff"],
		snpEff_genome =config["snpEff_genome"],
	shell: """
	#######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	module load snpEff/{version}
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar ${{SNPEFFHOME}}/SnpSift.jar dbnsfp -c {input.snpEff_config} -a {input.vcf} | java -Xmx${{MEM}}g -jar ${{SNPEFFHOME}}/snpEff.jar -t -canon {params.snpEff_genome} > {output.eff} 2> {log}
	perl {input.vcf2txt} {output.eff} >{output.txt}
	#######################
	"""
############
#	MakeList
############
rule FormatInput:
	input:	somatic=ALL_SOMATIC, 
		germline=ALL_GERMLINE,
		convertor= NGS_PIPELINE + "/scripts/" + config["annoInput"]
	output: 
		"annotation/AnnotationInput.anno", 
		"annotation/AnnotationInput.pph",
		"annotation/AnnotationInput.sift",
	log: "log/FormatInput"
	version: config["annovar"]
	params:
		rulename   = "FormatInput",
		batch      = config["job_annovar"],
	shell: """
	#######################
	module load annovar/{version}
	echo {input.germline}
	echo {input.somatic}
	LIST=`echo {input.germline} {input.somatic}|sed -e 's/,/ /g'`
	cut -f 1-5 ${{LIST}}|sort |uniq >"annotation/AnnotationInput"
	perl {input.convertor} "annotation/AnnotationInput" 2>{log}
	#######################
	"""
############
#	Custom Annotation
############
rule Annotation:
	input: 
		"annotation/AnnotationInput.anno",
		TableAnnovar=NGS_PIPELINE + "/scripts/" + config["Annovar"],
		custom     =NGS_PIPELINE + "/scripts/" + config["customAnno"]
	output:
		"annotation/AnnotationInput.docm"
	log: "log/Annovar"
	version: config["annovar"]
	params:
		rulename   = "Annotation",
		batch      = config["job_annovar"],
		RefData    = config["annovar_data"],
		build      = config["build"],
	shell: """
	#######################
	module load annovar/{version}
	perl {input.TableAnnovar} annotation AnnotationInput {input.custom} 2>>{log}
	#######################
	"""
############
#       SIFT
############
rule SIFT:
	input:
		sift="annotation/AnnotationInput.sift",
		convertor  = NGS_PIPELINE + "/scripts/" + config["SiftParse"]
	output: "annotation/AnnotationInput.sift.out"
	log: "log/SIFT"
	version: config["SIFT"]
	params:
		rulename   = "SIFT",
		batch      = config["job_SIFT"],
		build      = config["SIFTbuild"]
	shell: """
	#######################
	module load python/2.7.4
	module load SIFT/{version}
	DIR=`pwd`
	cd ${{DIR}}/`dirname {input.sift}`
	FILE=`basename {input.sift}`
	SIFT_exome_nssnvs.pl -i ${{FILE}} -d /fdb/sift/Human_db_37 -o $SIFT_SCRATCHDIR -z ${{DIR}}/`dirname {input.sift}`/${{FILE}}.sift_predictions.tsv
	perl {input.convertor} ${{DIR}}/`dirname {input.sift}`/${{FILE}}.sift_predictions.tsv >${{DIR}}/`dirname {input.sift}`/${{FILE}}.out
	#######################
	"""
############
#       PPH2
############
rule PPH2:
	input:
		pph="annotation/AnnotationInput.pph",
		convertor  = NGS_PIPELINE + "/scripts/" + config["PPH2Parse"]
	output: "annotation/AnnotationInput.pph2.out"
	log: "log/PPH2"
	version: config["polyphen2"]
	params:
		rulename   = "PPH2",
		batch      = config["job_PPH2"],
	shell: """
	#######################
	module load polyphen2/{version}
	mapsnps.pl -c -g hg19 -U -y {input.pph}.intermediate {input.pph} 2>{log}
	pph_swarm.pl {input.pph}.intermediate -d /scratch/`whoami`/${{RANDOM}}${{RANDOM}} -o annotation/AnnotationInput.pph2.intermediate.txt --partition ${{SLURM_JOB_PARTITION}} --block 
	perl {input.convertor}  annotation/AnnotationInput.pph2.intermediate.txt >{output} 2>>{log}
	rm -rf {input.pph}intermediate annotation/AnnotationInput.pph2.intermediate.txt
	mv pph_* log/ 
	#######################
	"""
############
#	Combine Annotation
############
rule CombineAnnotation:
	input:
		anno="annotation/AnnotationInput.docm", 
		sift="annotation/AnnotationInput.sift.out", 
		pph2="annotation/AnnotationInput.pph2.out",
		convertor  = NGS_PIPELINE + "/scripts/" + config["CombineAnno"],
		geneanno   = NGS_PIPELINE + "/scripts/" + config["GeneAnno"]
	output: "annotation/AnnotationInput.annotations.final.txt"
	log: "log/CombineAnnotation"
	version: "1.0"
	params:
		rulename   = "combine",
		batch	   = config["job_Combine"],
		dataDir    = config["annovar_data"]
	shell: """
	#######################
	echo "annotation/AnnotationInput
annotation/AnnotationInput.anno.gene
annotation/AnnotationInput.anno.exac.3
annotation/AnnotationInput.anno.clinseq
annotation/AnnotationInput.anno.cadd
annotation/AnnotationInput.sift.out
annotation/AnnotationInput.pph2.out
annotation/AnnotationInput.anno.clinvar
annotation/AnnotationInput.hgmd
annotation/AnnotationInput.match
annotation/AnnotationInput.docm
annotation/AnnotationInput.mcg
annotation/AnnotationInput.anno.pcg" >annotation/list
	perl {input.convertor} annotation/list >{output}.tmp
	perl {input.geneanno} {params.dataDir}/hg19_ACMG.txt {output}.tmp >{output}
	rm -rf {output}.tmp
	#######################
	"""
############
#	Add Annotation back to sample level file 
############
rule AttachAnnotation:
	input:
		txt="{sample}/annotation/{sample}.{base}",
		ref="annotation/AnnotationInput.annotations.final.txt",
		convertor  = NGS_PIPELINE + "/scripts/" + config["addBack"]
	output:
		txt="{sample}/annotation/{sample}.{base}.annotated.txt"
	log: "log/attach_annotation"
	version: "1.0"
	params:
		rulename   = "add",
		batch      = config["job_addbackann"],
	shell: """
	#######################
	perl {input.convertor} {input.ref} {input.txt} >{output.txt} 2>{log}
	#######################
	"""
############
#       Expressed
############
rule Expressed:
	input: 
		RNASeq = lambda wildcards: expressedPairs[wildcards.sample],
		Mutation="{sample}/annotation/{sample}.{base}.annotated.txt",
		convertor = NGS_PIPELINE + "/scripts/" + config["mpileup"]
	output: "{sample}/annotation/{sample}.{base}.annotated.expressed.txt"
	log: "{sample}/pbs_log/expressed"
	version: 1.0
	params:
		rulename  = "Expressed",
		batch     = config["job_expressed"],
		convertor = config["mpileup"]
	shell: """
	#######################
	perl {input.convertor} {input.Mutation} {input.RNASeq} > {output} 2>{log}
	#######################
	"""
############
#
############
