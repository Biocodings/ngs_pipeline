RNASEQ_BAM =[]
RNASEQ_BAM1 =[]
RNASEQ_FUSION1=[]
RNASEQ_FUSION =[]
CUFFLINKS=[]

SUB2RNA = {}
for subject,samples in config['RNASeq'].items():
	for sample in samples:
		SUB2RNA[sample]=subject

for subject  in config['RNASeq'].keys():
	for sample in config['RNASeq'][subject]:
		ALL_FASTQC += [subject+"/"+sample+"/qc/fastqc/"+sample+"_R2_fastqc.html"]
		RNASEQ_BAM += [subject+"/"+sample+"/tophat_"+sample+"/accepted_hits.bam"]
		RNASEQ_BAM1 += [subject+"/"+sample+"/"+sample+".star.final.bam"]	
		RNASEQ_BAM1 += [subject+"/"+sample+"/"+sample+".star.final.bam.bai"]
		RNASEQ_FUSION1 += [subject+"/"+sample+"/tophatfusion_out/result.txt"]
		RNASEQ_FUSION1 += [subject+"/"+sample+"/fusion/fusion-catcher.txt"]
		RNASEQ_FUSION += [subject+"/"+sample+"/fusion/defuse.raw.txt"]
		RNASEQ_FUSION += [subject+"/"+sample+"/fusion/defuse.filtered.txt"]
		ALL_QC      += [subject+"/"+sample+"/qc/"+sample+".star.flagstat.txt"]
		ALL_QC      += [subject+"/"+sample+"/qc/"+sample+".star.hotspot.depth"]
		ALL_QC      += [subject+"/"+sample+"/qc/"+sample+".star.gt"]
		add_to_SUBJECT_ANNO(subject, "rnaseq", [subject+"/"+sample+"/calls/"+sample+".hapcaller.annotated.txt"])
		for gtf in config['GTF']:
			CUFFLINKS += [subject+"/"+sample+"/cufflinks_"+gtf+"/genes.fpkm_tracking_log2"]
RNA_CALLS =[]

#add_to_SUBJECT_ANNO(subject, "rnaseq", [subject+"/"+sample+"/calls/"+sample+".hapcaller.annotated.txt"])
for Subject in config['RNASeq']:
	if Subject in config['RNASeq']:
		if Subject in SUBJECT_VCFS:
			SUBJECT_VCFS[Subject] += ["{subject}/{sample}/calls/{sample}.hapcaller.snpEff.txt".format(subject=SUB2RNA[s], sample=s) for s in config['RNASeq'][Subject]]
		else:
			SUBJECT_VCFS[Subject] = []
			SUBJECT_VCFS[Subject] += ["{subject}/{sample}/calls/{sample}.hapcaller.snpEff.txt".format(subject=SUB2RNA[s], sample=s) for s in config['RNASeq'][Subject]]
		RNA_CALLS += ["{subject}/{sample}/calls/{sample}.hapcaller.annotated.txt".format(subject=SUB2RNA[s], sample=s) for s in config['RNASeq'][Subject]]	
		if Subject in SUB_HOT:
			SUB_HOT[Subject] += ["{subject}/{sample}/qc/{sample}.star.hotspot.depth".format(subject=SUB2RNA[s], sample=s) for s in config['RNASeq'][Subject]]
			SUB_LOH[Subject] += ["{subject}/{sample}/qc/{sample}.star.loh".format(subject=SUB2RNA[s], sample=s) for s in config['RNASeq'][Subject]]
			SUB_COV[Subject] += ["{subject}/{sample}/qc/{sample}.star.coverage.txt".format(subject=SUB2RNA[s], sample=s) for s in config['RNASeq'][Subject]]
		else:
			SUB_HOT[Subject] = []
			SUB_LOH[Subject] = []
			SUB_COV[Subject] = []
			SUB_HOT[Subject] += ["{subject}/{sample}/qc/{sample}.star.hotspot.depth".format(subject=SUB2RNA[s], sample=s) for s in config['RNASeq'][Subject]]
			SUB_LOH[Subject] += ["{subject}/{sample}/qc/{sample}.star.loh".format(subject=SUB2RNA[s], sample=s) for s in config['RNASeq'][Subject]]
			SUB_COV[Subject] += ["{subject}/{sample}/qc/{sample}.star.coverage.txt".format(subject=SUB2RNA[s], sample=s) for s in config['RNASeq'][Subject]]
############
#       RNASeq All
############
rule RNASeq:
	input:
		RNASEQ_BAM,
		RNASEQ_FUSION,
		CUFFLINKS,
		RNA_CALLS,
		expand("{subject}/qc/{subject}.hotspot_coverage.png", subject=config['RNASeq']),
		expand("{subject}/qc/{subject}.coveragePlot.png", subject=config['RNASeq']),
		expand("{subject}/qc/{subject}.circos.png", subject=config['RNASeq']),

	output:
		touch("RNASeq.done")
	message: "End of RNASeq"
	shell: """
	#######################
	echo "Everything is done on RNASeq samples" >{output}
	#######################
	"""
############
#	Tophat
############
rule tophat:
	input:
		R1=DATA_DIR + "/{sample}/{sample}_R1.fastq.gz",
		R2=DATA_DIR + "/{sample}/{sample}_R2.fastq.gz",
	output: 
		"{base}/{sample}/tophat_{sample}/accepted_hits.bam", 
		"{base}/{sample}/tophat_{sample}/accepted_hits.bam.bai"
	log: "log/tophat.{sample}"
	version: config["tophat"]
#	message: "Running tophat on {wildcards.sample}"
	params:
		rulename  = "tophat",
		batch     = config["job_tophat"],
		ref=config['Bowtie2Index']
	shell: """
	#######################
	module load tophat/{version}
	tophat -p ${{SLURM_CPUS_ON_NODE}} -o /lscratch/${{SLURM_JOBID}} --keep-fasta-order --rg-id {wildcards.sample} --no-coverage-search --rg-sample {wildcards.sample} --rg-library {wildcards.sample} --rg-platform ILLUMINA --fusion-search --fusion-min-dist 100000 --mate-inner-dist 84 --mate-std-dev 74 {params.ref} {input.R1} {input.R2} 2>{log}
	mv -f /lscratch/${{SLURM_JOBID}}/* {wildcards.base}/{wildcards.sample}/tophat_{wildcards.sample}/
	samtools index {wildcards.base}/{wildcards.sample}/tophat_{wildcards.sample}/accepted_hits.bam

	#######################
	"""
############
#       Tophat-fusion
############
rule tophat_fusion:
	input: 
		"{base}/{sample}/tophat_{sample}/accepted_hits.bam",
		"{base}/{sample}/tophat_{sample}/accepted_hits.bam.bai"	
	output: 
		"{base}/{sample}/tophatfusion_out/result.txt"
	version: config["tophat"]
	params:
		rulename = "tp",
		batch    =config['job_tophatPost'],
		ref      =config['BowtieIndex'],
		bowtie   =config['bowtie'],
		tp_ref   =config['tophat_post_ref']
	shell: """
	#######################
	module load tophat/{version}
	module load bowtie/{params.bowtie}
	module load blast
	cd {wildcards.base}/{wildcards.sample}/
	rm -f blast ensGene.txt ensGtp.txt mcl refGene.txt
	ln -s {params.tp_ref}/* .
	tophat-fusion-post -p ${{SLURM_CPUS_ON_NODE}} --num-fusion-pairs 1 {params.ref}
	rm blast ensGene.txt ensGtp.txt mcl refGene.txt
	ln -s ../tophatfusion_out/result.html fusion/tophat-fusion.html
	ln -s ../tophatfusion_out/result.txt  fusion/tophat-fusion.txt
	#######################
	"""
############
#       Cufflinks
############
rule cufflinks:
	input:
		bam="{base}/{sample}/tophat_{sample}/accepted_hits.bam",
		bai="{base}/{sample}/tophat_{sample}/accepted_hits.bam.bai",
		convertor =NGS_PIPELINE + "/scripts/" +config['transformlog2_FPKM'],
		ref=lambda wildcards: config['GTF'][wildcards.gtf]
	output:
		"{base}/{sample}/cufflinks_{gtf}/genes.fpkm_tracking_log2",
		"{base}/{sample}/cufflinks_{gtf}/isoforms.fpkm_tracking_log2"
	log: "log/cufflinks.{sample}"
	version: config['cufflinks']
	params:
		rulename   = "cuff",
		batch      =config['job_cufflinks']
	shell: """
	#######################
	module load cufflinks/{version}
	cufflinks -p ${{SLURM_CPUS_ON_NODE}} -G {input.ref} --max-bundle-frags 8000000000000 --max-bundle-length 10000000 -o {wildcards.base}/{wildcards.sample}/cufflinks_{wildcards.gtf} {input.bam} 2>{log}
	/usr/bin/python {input.convertor} genes {wildcards.base}/{wildcards.sample}/cufflinks_{wildcards.gtf}/genes.fpkm_tracking {wildcards.base}/{wildcards.sample}/cufflinks_{wildcards.gtf}/genes.fpkm_tracking_log2
	/usr/bin/python {input.convertor} isoforms {wildcards.base}/{wildcards.sample}/cufflinks_{wildcards.gtf}/isoforms.fpkm_tracking {wildcards.base}/{wildcards.sample}/cufflinks_{wildcards.gtf}/isoforms.fpkm_tracking_log2 
	#######################
	"""
############
#       Fusioncatcher
############
rule fusioncatcher:
	input:
		R1=DATA_DIR + "/{sample}/{sample}_R1.fastq.gz",
		R2=DATA_DIR + "/{sample}/{sample}_R2.fastq.gz",
	output: 
		"{base}/{sample}/fusion/fusion-catcher.txt"
	log: "log/fc.{sample}"
	version: config['fusioncatcher']
	message: "Running FusionCatcher on {wildcards.sample}"
	params:
		rulename = "fc",
		batch    = config['job_fusioncatch']
	shell: """
	#######################
	module load fusioncatcher/{version}
	fusioncatcher -p ${{SLURM_CPUS_ON_NODE}} -i {input.R1},{input.R2} -o /lscratch/${{SLURM_JOBID}}/ --skip-filter-mt -s '2,2,2,2,2' -a '10,10,10,10,10' 2>{log}
	cp /lscratch/${{SLURM_JOBID}}/final-list_candidate-fusion-genes.GRCh37.txt {wildcards.base}/{wildcards.sample}/fusion/fusion-catcher.txt
	#######################
	"""
############
#       deFuse
############
rule deFuse:
	input:
		R1=DATA_DIR + "/{sample}/{sample}_R1.fastq.gz",
		R2=DATA_DIR + "/{sample}/{sample}_R2.fastq.gz",
		config=config["defuse_config"],
	output:
		"{base}/{sample}/fusion/defuse.raw.txt",
		"{base}/{sample}/fusion/defuse.filtered.txt",
		"{base}/{sample}/fusion/defuse.Reads/defuse.done"
	log: "log/deFuse.{sample}"
	version: config["defuse"]
	message: "Running deFuse on {wildcards.sample}"
	params:
		rulename = "deFuse",
		batch    = config["job_deFuse"]
	shell: """
	#######################
	module load defuse/{version}
	
	export TMPDIR="{wildcards.base}/{wildcards.sample}/fusion/temp/R"
	export TMP="{wildcards.base}/{wildcards.sample}/fusion/temp/R"
	export TEMP="{wildcards.base}/{wildcards.sample}/fusion/temp/R"
	
	gunzip -c {input.R1} >{wildcards.base}/{wildcards.sample}/fusion/{wildcards.sample}_R1.fastq &
	gunzip -c {input.R2} >{wildcards.base}/{wildcards.sample}/fusion/{wildcards.sample}_R2.fastq &
	wait
	defuse.pl -c {input.config} \
		-1 {wildcards.base}/{wildcards.sample}/fusion/{wildcards.sample}_R1.fastq\
		-2 {wildcards.base}/{wildcards.sample}/fusion/{wildcards.sample}_R2.fastq\
		-p ${{SLURM_CPUS_ON_NODE}} \
		-n {wildcards.sample}\
		-o {wildcards.base}/{wildcards.sample}/fusion/temp\
		-s direct 2>{log} 
	cp {wildcards.base}/{wildcards.sample}/fusion/temp/results.filtered.tsv  {wildcards.base}/{wildcards.sample}/fusion/defuse.filtered.txt
	cp {wildcards.base}/{wildcards.sample}/fusion/temp/results.tsv           {wildcards.base}/{wildcards.sample}/fusion/defuse.raw.txt
	
	for ID in `cut -f1 {wildcards.base}/{wildcards.sample}/fusion/defuse.filtered.txt|grep -v cluster_id`;
	do 
		echo "get_reads.pl -c {input.config} -o {wildcards.base}/{wildcards.sample}/fusion/temp/ -i ${{ID}} >{wildcards.base}/{wildcards.sample}/fusion/defuse.Reads/${{ID}}.txt" 
	done >{wildcards.base}/{wildcards.sample}/fusion/cmd.swarm
	cat {wildcards.base}/{wildcards.sample}/fusion/cmd.swarm | parallel -j ${{SLURM_CPUS_ON_NODE}} --no-notice	
	touch {wildcards.base}/{wildcards.sample}/fusion/defuse.Reads/defuse.done	
	rm -rf {wildcards.base}/{wildcards.sample}/fusion/{wildcards.sample}_R1.fastq {wildcards.base}/{wildcards.sample}/fusion/{wildcards.sample}_R2.fastq 
	rm -rf {wildcards.base}/{wildcards.sample}/fusion/temp {wildcards.base}/{wildcards.sample}/fusion/cmd.swarm
	#######################
	"""
############
#       STAR
############
rule STAR:
	input:
		R1=DATA_DIR + "/{sample}/{sample}_R1.fastq.gz",
		R2=DATA_DIR + "/{sample}/{sample}_R2.fastq.gz",
		ref=config["reference"],
	output:
		temp("{base}/{sample}/{sample}.star.bam"),
		temp("{base}/{sample}/{sample}.star.bam.bai")
	version: config["STAR"]
	message: "Running STAR on {wildcards.sample}"
	params:
		rulename  = "STAR",
		batch     = config['job_STAR'],
#		star_ref  = "/data/khanlab/apps/RNASeq_pipeline/Annotation/hg19_Broad_resource_bundle/STAR_hg19_index",
		star_ref  = config['STAR_ref'],
		awk       = NGS_PIPELINE + "/scripts/SJDB.awk",
		home      = WORK_DIR,
		picard    = config['picard']
	shell: """
	#######################
	module load STAR/{version}
	
	cd /lscratch/${{SLURM_JOBID}}/
	# run 1st pass
	STAR --outTmpDir STEP1 \
		--genomeDir {params.star_ref} \
		--readFilesIn {input.R1} {input.R2} \
		--readFilesCommand zcat\
		--outFileNamePrefix {wildcards.sample} \
		--runThreadN ${{SLURM_CPUS_ON_NODE}} \
		--outFilterMismatchNmax 2
	echo "Finished Step 1"	

	# make splice junctions database file out of SJ.out.tab, filter out non-canonical junctions
	mkdir GenomeForPass2
	awk -f {params.awk} {wildcards.sample}SJ.out.tab > GenomeForPass2/{wildcards.sample}.out.tab.Pass1.sjdb
	echo "Finished Step 2"

	# generate genome with junctions from the 1st pass
	STAR --outTmpDir STEP1\
		--genomeDir GenomeForPass2\
		--runMode genomeGenerate\
		--genomeSAindexNbases 8\
		--genomeFastaFiles {input.ref}\
		--sjdbFileChrStartEnd GenomeForPass2/{wildcards.sample}.out.tab.Pass1.sjdb\
		--sjdbOverhang 100\
		--runThreadN ${{SLURM_CPUS_ON_NODE}}
	echo "Finished Step 3"

	# run 2nd pass with the new genome
	STAR --outTmpDir STEP1\
		--genomeDir GenomeForPass2\
		--runThreadN ${{SLURM_CPUS_ON_NODE}}\
		--outSAMattributes All\
		--genomeLoad LoadAndKeep\
		--readFilesIn {input.R1} {input.R2}\
		--readFilesCommand zcat\
		--outFileNamePrefix {wildcards.sample}_pass2
	echo "Finished Step 4"	
	
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	module load picard/{params.picard}
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $PICARDJARPATH/AddOrReplaceReadGroups.jar\
        VALIDATION_STRINGENCY=SILENT\
        INPUT={wildcards.sample}_pass2Aligned.out.sam\
        OUTPUT={params.home}/{wildcards.base}/{wildcards.sample}/{wildcards.sample}.star.bam\
        SORT_ORDER=coordinate RGLB={wildcards.sample} RGPU={wildcards.sample} RGPL=ILLUMINA RGSM={wildcards.sample} RGCN=khanlab

	echo "Finished Step 5"
	module load samtools
	samtools index {params.home}/{wildcards.base}/{wildcards.sample}/{wildcards.sample}.star.bam
	#######################
	"""
############
#       GATK_RNASeq
############
############
#       GATK Best Practices
############
rule GATK_RNASeq:
	input:  bam="{base}/{sample}/{sample}.star.dd.bam",
		bai="{base}/{sample}/{sample}.star.dd.bam.bai",
		ref=config["reference"],
		phase1=config["1000G_phase1"],
		mills=config["Mills_and_1000G"]
	output:
		bam="{base}/{sample}/{sample}.star.final.bam",
		index="{base}/{sample}/{sample}.star.final.bam.bai",
	log:    "log/gatk.{sample}"
	version: config["GATK"]
	message: "Running GATK Best practices on {input.bam}"
	params:
		rulename  = "gatk",
		batch     = config["job_gatk"]
	shell: """
	#######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	module load GATK/{version}
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T SplitNCigarReads -R {input.ref} -I {input.bam} -o /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.trim.bam -rf ReassignOneMappingQuality -RMQF 255 -RMQT 60 -U ALLOW_N_CIGAR_READS > {log} 2>&1
	
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T RealignerTargetCreator -R {input.ref} -known {input.phase1} -known {input.mills} -I /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.trim.bam -o /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.realignment.intervals >> {log} 2>&1
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T IndelRealigner -R {input.ref} -known {input.phase1} -known {input.mills} -I /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.trim.bam --targetIntervals /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.realignment.intervals -o /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.lr.bam >>{log} 2>&1
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T BaseRecalibrator -R {input.ref} -knownSites {input.phase1} -knownSites {input.mills} -I /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.lr.bam -o /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.recalibration.matrix.txt >>{log} 2>&1
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T PrintReads -R {input.ref} -I /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.lr.bam -o {output.bam} -BQSR /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.recalibration.matrix.txt >>{log} 2>&1
	mv {wildcards.base}/{wildcards.sample}/{wildcards.sample}.star.final.bai {output.index}
	######################
	"""
############
# RNASeq Hapcaller
############
rule HapCall_RNASeq:
	input:
		bam="{base}/{sample}/{sample}.star.final.bam",
		bai="{base}/{sample}/{sample}.star.final.bam.bai",
		ref=config["reference"],
		dbsnp=config["dbsnp"]
	output:
		vcf="{base}/{sample}/calls/{sample}.hapcaller.raw.vcf"
	log: "log/hapcaller.{sample}"
	version: config["GATK"]
	message: "Haplotype Caller on {wildcards.sample}"
	params:
		rulename = "HC",
		batch    = config["job_gatk"]
	shell: """
        #######################
	MEM=`echo "{params.batch}" |perl -n -e'/--mem=(\d+)/ && print \$1'`
	module load GATK/{version}
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T HaplotypeCaller -R {input.ref} -I {input.bam} -o /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.vcf --dbsnp {input.dbsnp} -dontUseSoftClippedBases -stand_call_conf 30 -stand_emit_conf 30 -log {log}
	java -Xmx${{MEM}}g -Djava.io.tmpdir=/lscratch/${{SLURM_JOBID}} -jar $GATK_JAR -T VariantFiltration -R {input.ref} -V /lscratch/${{SLURM_JOBID}}/{wildcards.sample}.vcf -window 35 -cluster 3 --filterExpression "FS > 30.0 || QD < 2" -filterName "RNASeqFilters_FS_QD" -o {output.vcf}
        #######################
	"""
############
# Coverage
############
rule coverage:
	input:
		bam="{subject}/{sample}/{sample}.star.final.bam",
		bai="{subject}/{sample}/{sample}.star.final.bam.bai",
		interval=config["refSeq_bed"]
	output:
		"{subject}/{sample}/qc/{sample}.star.coverage.txt"
	log: "log/coverage.{sample}"
	version: config["bedtools"]
	message: "Running Coverage on {input.bam}"
	params:
		rulename = "coverage",
		batch    = config["job_bedtools"]
	shell: """
	#######################
	module load bedtools/{version}
	bedtools coverage -abam {input.bam} -b {input.interval} -hist |grep "^all" > {output}
	#######################
	"""
